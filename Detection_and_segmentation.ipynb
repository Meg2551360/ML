{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80rM_bM0Ze5Q",
        "outputId": "c01fa5a3-409b-4280-cfdb-8b6b45eb8da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.147-py3-none-any.whl (606 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.2/606.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: ultralytics\n",
            "Successfully installed ultralytics-8.0.147\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "from IPython.display import Image as Image2\n",
        "from IPython import display\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import torch\n",
        "from PIL import Image as Image1\n",
        "import gc"
      ],
      "metadata": {
        "id": "Vn54VAvZZnmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Устанавливаем Yolo V5 (large) для распознавания\n",
        "\n",
        "detector = torch.hub.load('ultralytics/yolov5', 'custom',\n",
        "                              path = 'yolov5m.pt') #'yolov5s.pt'\n",
        "print('#'*60)\n",
        "print(f\"Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'}), OpenCV: {cv2.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nl3pWAJZnig",
        "outputId": "50c1a0f8-5724-405d-a3c5-d7e8b5cee94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['gitpython>=3.1.30'] not found, attempting AutoUpdate...\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 188.5/188.5 kB 5.6 MB/s eta 0:00:00\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 308.3 MB/s eta 0:00:00\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.32 smmap-5.0.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 4.0s, installed 1 package: ['gitpython>=3.1.30']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 2023-8-5 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt to yolov5m.pt...\n",
            "100%|██████████| 40.8M/40.8M [00:00<00:00, 191MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############################################################\n",
            "Using torch 2.0.1+cu118 (CPU), OpenCV: 4.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Список детектируемых классов\n",
        "coco_labels = '''person\n",
        "bicycle\n",
        "car\n",
        "motorcycle\n",
        "airplane\n",
        "bus\n",
        "train\n",
        "truck\n",
        "boat\n",
        "traffic light\n",
        "fire hydrant\n",
        "street sign\n",
        "stop sign\n",
        "parking meter\n",
        "bench\n",
        "bird\n",
        "cat\n",
        "dog\n",
        "horse\n",
        "sheep\n",
        "cow\n",
        "elephant\n",
        "bear\n",
        "zebra\n",
        "giraffe\n",
        "hat\n",
        "backpack\n",
        "umbrella\n",
        "shoe\n",
        "eye glasses\n",
        "handbag\n",
        "tie\n",
        "suitcase\n",
        "frisbee\n",
        "skis\n",
        "snowboard\n",
        "sports ball\n",
        "kite\n",
        "baseball bat\n",
        "baseball glove\n",
        "skateboard\n",
        "surfboard\n",
        "tennis racket\n",
        "bottle\n",
        "plate\n",
        "wine glass\n",
        "cup\n",
        "fork\n",
        "knife\n",
        "spoon\n",
        "bowl\n",
        "banana\n",
        "apple\n",
        "sandwich\n",
        "orange\n",
        "broccoli\n",
        "carrot\n",
        "hot dog\n",
        "pizza\n",
        "donut\n",
        "cake\n",
        "chair\n",
        "couch\n",
        "potted plant\n",
        "bed\n",
        "mirror\n",
        "dining table\n",
        "window\n",
        "desk\n",
        "toilet\n",
        "door\n",
        "tv\n",
        "laptop\n",
        "mouse\n",
        "remote\n",
        "keyboard\n",
        "cell phone\n",
        "microwave\n",
        "oven\n",
        "toaster\n",
        "sink\n",
        "refrigerator\n",
        "blender\n",
        "book\n",
        "clock\n",
        "vase\n",
        "scissors\n",
        "teddy bear\n",
        "hair drier\n",
        "toothbrush\n",
        "hair brush'''.split()"
      ],
      "metadata": {
        "id": "bXPHe1o7ZngC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# функция преобразования объекта JavaScript в изображение OpenCV image - надо запускать также для следующего раздела\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # декодируем изображение из формата base64\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # конвертируем байты в numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # декодируем numpy array в изображение OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# функция для преобразования изображения с прямоугольником OpenCV Rectangle bounding box image в байтовую строку base64 чтобы вывести в видеопоток\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # конвертируем массив в изображение PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # преобразуем bbox в формат png для возврата из функции с помощью return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # форматируем возвращаемую с помощью return строку\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "JrLakOC-ZndS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Используем код на JavaScript для захвата потока с нашей вебкамеры и передачи данных на облачный компьютер - надо запускать также для следующего раздела\n",
        "def video_stream_js():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'Чтобы завершить, щёлкните мышкой на данном видео</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display.display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "_cWjWCO7Znat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Детекция"
      ],
      "metadata": {
        "id": "OKIVR-2vcqpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# получаем прямоугольники(баундбоксы) - в кадре должен быть человек\n",
        "# очищаем память\n",
        "gc.collect()\n",
        "\n",
        "# начинаем захват видео с камеры\n",
        "video_stream_js()\n",
        "\n",
        "# Создаём надпись\n",
        "label_html = 'Захват изображения...'\n",
        "\n",
        "# инициализируем пустые прямоугольники выделения\n",
        "bbox = ''\n",
        "count = 0\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # конвертируем поток, передаваемый через JS, в изображение OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # создаём пустой массив, в котором будет отображаться детекция объектов\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # переводим изображение в серое для детекции\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # детектирование\n",
        "    cur = detector(img) #img\n",
        "    yolo_preds = cur.xyxy[0].cpu().numpy()\n",
        "\n",
        "    # получение коодинат прямоугольников\n",
        "    boxes = yolo_preds[:, :4]  # xmin, ymin, xmax, ymax\n",
        "    confs = yolo_preds[:, 4]\n",
        "    labels = yolo_preds[:, 5]\n",
        "\n",
        "    fst_box_flag = 1\n",
        "\n",
        "    # получаем конкретные прямоугольники\n",
        "    for box, conf, label in zip(boxes, confs, labels):\n",
        "        if coco_labels[int(label)] == 'person' and fst_box_flag == 1: #\n",
        "             y1, y2, x1, x2 = int(box[1]), int(box[3]), int(box[0]), int(box[2])\n",
        "             bbox_array = cv2.rectangle(bbox_array,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "             fst_box_flag = 0\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array) #bbox_array\n",
        "    # записываем в конкретные массивы изображения с прямоугольниками\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "jncoL5_OaIou",
        "outputId": "de3cc99b-880c-4504-a0d2-d267368f0c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "\n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "\n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "\n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "\n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "\n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML =\n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'Чтобы завершить, щёлкните мышкой на данном видео</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "\n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "\n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "\n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "\n",
              "      return {'create': preShow - preCreate,\n",
              "              'show': preCapture - preShow,\n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://drive.google.com/file/d/1mkjCl3jJS6CLBpjtT8lD4JrLdFeubEX2/view?usp=sharing"
      ],
      "metadata": {
        "id": "_7RnKYboR7pz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сегментация"
      ],
      "metadata": {
        "id": "OhEDZqk4fd8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b shapemask https://github.com/tensorflow/tpu/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL3pJQQtcx83",
        "outputId": "669ddc59-d95a-4a89-90dd-4ed15503bb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tpu'...\n",
            "remote: Enumerating objects: 11310, done.\u001b[K\n",
            "remote: Counting objects: 100% (1512/1512), done.\u001b[K\n",
            "remote: Compressing objects: 100% (754/754), done.\u001b[K\n",
            "remote: Total 11310 (delta 877), reused 1271 (delta 720), pack-reused 9798\u001b[K\n",
            "Receiving objects: 100% (11310/11310), 47.03 MiB | 34.57 MiB/s, done.\n",
            "Resolving deltas: 100% (7915/7915), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# смещаем указатель в удобную папку\n",
        "%cd '/content/tpu/models/official/detection/utils/object_detection'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uh-fjlTc02n",
        "outputId": "9b3eda3c-bf70-44a6-906e-81129e14bb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tpu/models/official/detection/utils/object_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# переделываем часть строк в файлах Python чтобы не получать ошибку из-за дублирования названия функции из ultralytics\n",
        "with open ('/content/tpu/models/official/detection/utils/object_detection/visualization_utils.py', 'r') as f:\n",
        "  old_data = f.read()\n",
        "\n",
        "new_data = old_data.replace('from utils.object_detection import shape_utils', 'import shape_utils')\n",
        "\n",
        "with open ('/content/tpu/models/official/detection/utils/object_detection/visualization_utils.py', 'w') as f:\n",
        "  f.write(new_data)\n",
        "\n",
        "\n",
        "with open ('/content/tpu/models/official/detection/evaluation/coco_utils.py', 'r') as f:\n",
        "  old_data = f.read()\n",
        "\n",
        "new_data = old_data.replace('from utils import box_utils', 'from detection.utils1 import box_utils')\n",
        "\n",
        "with open ('/content/tpu/models/official/detection/evaluation/coco_utils.py', 'w') as f:\n",
        "  f.write(new_data)"
      ],
      "metadata": {
        "id": "qctLhHrfc0zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# переносим папку с функциями чтобы они не пересекались по названию с ultralytics\n",
        "!mv '/content/tpu/models/official/detection/utils/' '/content/tpu/models/official/detection/utils1/'"
      ],
      "metadata": {
        "id": "D-Fi9hi8c0tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "from PIL import Image as Image1\n",
        "import sys\n",
        "\n",
        "# добавляем системные пути чтобы найти модули\n",
        "sys.path.insert(0, '/content/tpu/models/official')\n",
        "sys.path.insert(0, '/content/tpu/models/official/detection')\n",
        "sys.path.insert(0, '/content/tpu/models/official/detection/utils')\n",
        "sys.path.insert(0, '/content/tpu/models/official/detection/utils/object_detection')\n",
        "sys.path.insert(0, '/content/tpu/models/official/detection/utils1')\n",
        "sys.path.insert(0, '/content/tpu/models/official/detection/utils1/object_detection')\n",
        "\n",
        "# теперь импортируем перемещённые модули\n",
        "from utils1.object_detection import visualization_utils\n",
        "from evaluation import coco_utils"
      ],
      "metadata": {
        "id": "kp-I4j07c-ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID_MAPPING = {\n",
        "    1: 'person',\n",
        "    2: 'bicycle',\n",
        "    3: 'car',\n",
        "    4: 'motorcycle',\n",
        "    5: 'airplane',\n",
        "    6: 'bus',\n",
        "    7: 'train',\n",
        "    8: 'truck',\n",
        "    9: 'boat',\n",
        "    10: 'traffic light',\n",
        "    11: 'fire hydrant',\n",
        "    13: 'stop sign',\n",
        "    14: 'parking meter',\n",
        "    15: 'bench',\n",
        "    16: 'bird',\n",
        "    17: 'cat',\n",
        "    18: 'dog',\n",
        "    19: 'horse',\n",
        "    20: 'sheep',\n",
        "    21: 'cow',\n",
        "    22: 'elephant',\n",
        "    23: 'bear',\n",
        "    24: 'zebra',\n",
        "    25: 'giraffe',\n",
        "    27: 'backpack',\n",
        "    28: 'umbrella',\n",
        "    31: 'handbag',\n",
        "    32: 'tie',\n",
        "    33: 'suitcase',\n",
        "    34: 'frisbee',\n",
        "    35: 'skis',\n",
        "    36: 'snowboard',\n",
        "    37: 'sports ball',\n",
        "    38: 'kite',\n",
        "    39: 'baseball bat',\n",
        "    40: 'baseball glove',\n",
        "    41: 'skateboard',\n",
        "    42: 'surfboard',\n",
        "    43: 'tennis racket',\n",
        "    44: 'bottle',\n",
        "    46: 'wine glass',\n",
        "    47: 'cup',\n",
        "    48: 'fork',\n",
        "    49: 'knife',\n",
        "    50: 'spoon',\n",
        "    51: 'bowl',\n",
        "    52: 'banana',\n",
        "    53: 'apple',\n",
        "    54: 'sandwich',\n",
        "    55: 'orange',\n",
        "    56: 'broccoli',\n",
        "    57: 'carrot',\n",
        "    58: 'hot dog',\n",
        "    59: 'pizza',\n",
        "    60: 'donut',\n",
        "    61: 'cake',\n",
        "    62: 'chair',\n",
        "    63: 'couch',\n",
        "    64: 'potted plant',\n",
        "    65: 'bed',\n",
        "    67: 'dining table',\n",
        "    70: 'toilet',\n",
        "    72: 'tv',\n",
        "    73: 'laptop',\n",
        "    74: 'mouse',\n",
        "    75: 'remote',\n",
        "    76: 'keyboard',\n",
        "    77: 'cell phone',\n",
        "    78: 'microwave',\n",
        "    79: 'oven',\n",
        "    80: 'toaster',\n",
        "    81: 'sink',\n",
        "    82: 'refrigerator',\n",
        "    84: 'book',\n",
        "    85: 'clock',\n",
        "    86: 'vase',\n",
        "    87: 'scissors',\n",
        "    88: 'teddy bear',\n",
        "    89: 'hair drier',\n",
        "    90: 'toothbrush',\n",
        "}\n",
        "category_index = {k: {'id': k, 'name': ID_MAPPING[k]} for k in ID_MAPPING}"
      ],
      "metadata": {
        "id": "ufEy1BRHc-Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use_tpu = True #@param {type:\"boolean\"}\n",
        "use_tpu = False # мы делаем на GPU, поэтому отключаем поддержку TPU\n",
        "if use_tpu:\n",
        "  import os\n",
        "  import pprint\n",
        "\n",
        "  assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "  session = tf.Session(TPU_ADDRESS, graph=tf.Graph())\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "else:\n",
        "  session = tf.Session(graph=tf.Graph())"
      ],
      "metadata": {
        "id": "o9lEMB7xc-QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_dir = 'gs://cloud-tpu-checkpoints/shapemask/1571767330' #@param {type:\"string\"}\n",
        "_ = tf.saved_model.loader.load(session, ['serve'], saved_model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Je7KSAFdJtQ",
        "outputId": "08f9da02-829a-4b52-b25e-b75cb90ad9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-687feb56762d>:2: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.saved_model.load` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_boxes_to_draw = 1   #@param {type:\"integer\"}\n",
        "# показываем только один прямоугольник\n",
        "\n",
        "min_score_thresh = 0.23    #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#минимальный балл(порог)\n",
        "\n",
        "# получаем прямоугольники(баундбоксы) и сегментацию - в кадре должен быть человек\n",
        "# очищаем память\n",
        "gc.collect()\n",
        "\n",
        "# начинаем захват видео с камеры\n",
        "video_stream_js()\n",
        "\n",
        "# Создаём надпись\n",
        "label_html = 'Захват видео...'\n",
        "\n",
        "# инициализируем пустые прямоугольники выделения\n",
        "bbox = ''\n",
        "count = 0\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # конвертируем поток, передаваемый через JS, в изображение OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # создаём пустой массив, в котором будет отображаться детекция объектов\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # переводим изображение в серое для детекции\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    cv2.rectangle(img, (25,25), (115,115), (128,0,128), thickness=2, lineType=8, shift=0)\n",
        "    cv2.putText(img, \"1T\", (30,90), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,0,255), 2)\n",
        "\n",
        "    #cv2_imshow('result', img)\n",
        "\n",
        "    # детектирование\n",
        "    height, width, _ = img.shape\n",
        "    Image1.fromarray(img).save(f\"/content/1.jpg\")\n",
        "\n",
        "    with open(f\"/content/1.jpg\", 'rb') as f:\n",
        "        np_image_string_idx = np.array([f.read()])\n",
        "\n",
        "    num_detections, detection_boxes, detection_classes, detection_scores, detection_masks, detection_outer_boxes, image_info = session.run(\n",
        "        ['NumDetections:0', 'DetectionBoxes:0', 'DetectionClasses:0', 'DetectionScores:0',\n",
        "         'DetectionMasks:0', 'DetectionOuterBoxes:0', 'ImageInfo:0'],\n",
        "        feed_dict={'Placeholder:0': np_image_string_idx})\n",
        "\n",
        "    num_detections = np.squeeze(num_detections.astype(np.int32), axis=(0,))\n",
        "    detection_boxes = np.squeeze(detection_boxes / min(image_info[0, 2]), axis=(0,))[0:num_detections]\n",
        "    detection_outer_boxes = np.squeeze(detection_outer_boxes / min(image_info[0, 2]), axis=(0,))[0:num_detections]\n",
        "    detection_scores = np.squeeze(detection_scores, axis=(0,))[0:num_detections]\n",
        "    detection_classes = np.squeeze(detection_classes.astype(np.int32), axis=(0,))[0:num_detections]\n",
        "    instance_masks = np.squeeze(detection_masks, axis=(0,))[0:num_detections]\n",
        "\n",
        "    # Используем внешние прямоугольники (баундбоксы) и сегментируем\n",
        "    ymin, xmin, ymax, xmax = np.split(detection_outer_boxes, 4, axis=-1)\n",
        "    processed_boxes = np.concatenate([xmin, ymin, xmax - xmin, ymax - ymin], axis=-1)\n",
        "    segmentations = coco_utils.generate_segmentation_from_masks(instance_masks, processed_boxes, height, width)\n",
        "\n",
        "    bbox_array = visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        img * 1,\n",
        "        detection_boxes,\n",
        "        detection_classes,\n",
        "        detection_scores,\n",
        "        category_index,\n",
        "        instance_masks=segmentations, # инстанс сегментация\n",
        "        use_normalized_coordinates=False,\n",
        "        max_boxes_to_draw=max_boxes_to_draw,\n",
        "        min_score_thresh=min_score_thresh\n",
        "        )\n",
        "    bbox_array = np.concatenate((bbox_array, bbox_array[:,:,0].reshape(height, width, 1)), axis = 2)\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array) #bbox_array\n",
        "\n",
        "    # записываем в конкретные массивы изображения с прямоугольниками и сегментацией\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "r8WZelFbnMhx",
        "outputId": "af2d9c92-5085-4658-f6c9-e929fad96090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "\n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "\n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "\n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "\n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "\n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML =\n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'Чтобы завершить, щёлкните мышкой на данном видео</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "\n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "\n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "\n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "\n",
              "      return {'create': preShow - preCreate,\n",
              "              'show': preCapture - preShow,\n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://drive.google.com/file/d/1jEzYjF70KMxPGw27YXRPsVaehc51vW0D/view?usp=sharing"
      ],
      "metadata": {
        "id": "MPsiun3YRdtV"
      }
    }
  ]
}
